{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "\n",
    "from scipy import spatial\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# with open('training.json', \"r\") as f:\n",
    "#     d = json.loads(f.read())\n",
    "\n",
    "# train = pd.DataFrame.from_dict(d[\"data\"])\n",
    "# print(train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Load preprocessed dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(\"data/train.pickle\")\n",
    "train_context = pd.read_pickle(\"data/train_context.pickle\")\n",
    "dev = pd.read_pickle(\"data/dev.pickle\")\n",
    "dev_context = pd.read_pickle(\"data/dev_context.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(\"data/test.pickle\")\n",
    "test_context = pd.read_pickle(\"data/test_context.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop = True)\n",
    "dev = test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>context_idx</th>\n",
       "      <th>id</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>plausible_answers</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'text': 'Dangerously in Love', 'answer_start...</td>\n",
       "      <td>0</td>\n",
       "      <td>56d43c5f2ccc5a1400d830ab</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What was the first album Beyoncé released as a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'text': 'Houston, Texas', 'answer_start': 166}]</td>\n",
       "      <td>0</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'text': 'Mathew Knowles', 'answer_start': 360}]</td>\n",
       "      <td>0</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9605</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Who managed the Destiny's Child group?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'text': 'late 1990s', 'answer_start': 276}]</td>\n",
       "      <td>0</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'text': 'five', 'answer_start': 590}]</td>\n",
       "      <td>0</td>\n",
       "      <td>56d43c5f2ccc5a1400d830ad</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How many Grammy awards did Beyoncé win for her...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers  context_idx  \\\n",
       "0  [{'text': 'Dangerously in Love', 'answer_start...            0   \n",
       "1  [{'text': 'Houston, Texas', 'answer_start': 166}]            0   \n",
       "2  [{'text': 'Mathew Knowles', 'answer_start': 360}]            0   \n",
       "3      [{'text': 'late 1990s', 'answer_start': 276}]            0   \n",
       "4            [{'text': 'five', 'answer_start': 590}]            0   \n",
       "\n",
       "                         id is_impossible plausible_answers  \\\n",
       "0  56d43c5f2ccc5a1400d830ab         False               NaN   \n",
       "1  56bf6b0f3aeaaa14008c9601         False               NaN   \n",
       "2  56bf6b0f3aeaaa14008c9605         False               NaN   \n",
       "3  56bf6b0f3aeaaa14008c9602         False               NaN   \n",
       "4  56d43c5f2ccc5a1400d830ad         False               NaN   \n",
       "\n",
       "                                            question  \n",
       "0  What was the first album Beyoncé released as a...  \n",
       "1      In what city and state did Beyonce  grow up?   \n",
       "2             Who managed the Destiny's Child group?  \n",
       "3         In which decade did Beyonce become famous?  \n",
       "4  How many Grammy awards did Beyoncé win for her...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train(filename):\n",
    "    train = pd.read_json(filename)\n",
    "    df = pd.DataFrame()\n",
    "    context_count = 0\n",
    "    contexts = []\n",
    "    qa_dfs = []\n",
    "    for i in range(len(train)):\n",
    "        curr = train.loc[i, \"data\"]\n",
    "        lsts = curr[\"paragraphs\"] # each contains context, qas\n",
    "        for item in lsts:\n",
    "            contexts.append(item[\"context\"])\n",
    "            curr_qas = item[\"qas\"]\n",
    "            # columns in tmp_df: [u'answers', u'id', u'is_impossible', u'question', u'context_idx']\n",
    "            tmp_df = pd.DataFrame.from_records(curr_qas) \n",
    "            tmp_df[\"context_idx\"] = context_count\n",
    "            qa_dfs.append(tmp_df)\n",
    "            context_count += 1\n",
    "#         print(i)\n",
    "    context_df = pd.DataFrame.from_dict({\"context\": contexts})\n",
    "    df = pd.concat(qa_dfs)\n",
    "    return context_df, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(filename, obj):\n",
    "    pickling_on = open(filename + \".pickle\",\"wb\")\n",
    "    pickle.dump(obj, pickling_on)\n",
    "    pickling_on.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_context, train = read_train(\"training.json\")\n",
    "# save_pickle(\"train_context\", train_context)\n",
    "# save_pickle(\"train\", train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_context, dev = read_train(\"data/development.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(\"data/dev_context\", dev_context)\n",
    "save_pickle(\"data/dev\", dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_context, test = read_train(\"data/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"length of training is\", len(train))\n",
    "print(\"length of train context is \", len(train_context))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"length of test is\", len(test))\n",
    "print(\"length of test context is \", len(test_context))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(arr1, arr2):\n",
    "    return 1 - spatial.distance.cosine(arr1, arr2.T)\n",
    "#     return np.dot(arr1.T, arr2)/(LA.norm(arr1)*LA.norm(arr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column with similarity score in df\n",
    "def compute_sim(context_df, df):\n",
    "    df[\"similarity\"] = 0\n",
    "    res = []\n",
    "    for i in range(len(context_df)):\n",
    "        vectorizer = CountVectorizer(stop_words=\"english\") # build a vectorizer for each context\n",
    "        curr_context = [context_df.loc[i, \"context\"]]\n",
    "        vectorizer.fit(curr_context)\n",
    "        context_vec = vectorizer.transform(curr_context)\n",
    "        qas = df[df[\"context_idx\"] == i].reset_index()\n",
    "        for j in range(len(qas)):\n",
    "            q_vec = vectorizer.transform([qas.loc[j, \"question\"]])\n",
    "            if np.sum(q_vec) != 0:\n",
    "                qas.loc[j, \"similarity\"] = cosine_similarity(q_vec.toarray(), context_vec.toarray())\n",
    "            else:\n",
    "                qas.loc[j, \"similarity\"] = 0\n",
    "        res.append(qas)\n",
    "    res_df = pd.concat(res)\n",
    "    return res_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = compute_sim(train_context, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res[\"similarity\"] = train_res[\"similarity\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "true_sim = train_res[train_res[\"is_impossible\"] == True][\"similarity\"]\n",
    "false_sim = train_res[train_res[\"is_impossible\"] == False][\"similarity\"]\n",
    "bins = np.linspace(0.01, 1, 200)\n",
    "\n",
    "pyplot.hist(true_sim, bins, alpha=0.5, label='true')\n",
    "pyplot.hist(false_sim, bins, alpha=0.5, label='false')\n",
    "pyplot.xlabel('similarity score')\n",
    "pyplot.ylabel('question count')\n",
    "pyplot.legend(loc='upper right')\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res[train_res[\"is_impossible\"] == True][\"similarity\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res[train_res[\"is_impossible\"] == False][\"similarity\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = compute_sim(test_context, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_baseline(x, thred):\n",
    "    if x < thred:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.25\n",
    "test_res[\"predicted\"] = [predict_baseline(x, threshold) for x in test_res[\"similarity\"]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = test_res[[\"id\", \"predicted\"]].to_json(orient='values')[1:-1].replace(\"[\", \"\")\n",
    "output = \"{\" +  output.replace(\"]\", \"\") + \"}\"\n",
    "output = output.replace('\",', '\": ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_res[[\"id\", \"predicted\"]]\n",
    "submission.to_csv(\"baseline_submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dev_baseline.json', 'w') as f:\n",
    "    f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER tag parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 'The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\\\"Norman\\\" comes from \\\"Norseman\\\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nlp(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [item for item in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The -> \n",
      "Normans -> NORP\n",
      "( -> \n",
      "Norman -> PERSON\n",
      ": -> \n",
      "Nourmands -> \n",
      "; -> \n",
      "French -> NORP\n",
      ": -> \n",
      "Normands -> \n",
      "; -> \n",
      "Latin -> LANGUAGE\n",
      ": -> \n",
      "Normanni -> \n",
      ") -> \n",
      "were -> \n",
      "the -> \n",
      "people -> \n",
      "who -> \n",
      "in -> \n",
      "the -> DATE\n",
      "10th -> DATE\n",
      "and -> DATE\n",
      "11th -> DATE\n",
      "centuries -> DATE\n",
      "gave -> \n",
      "their -> \n",
      "name -> \n",
      "to -> \n",
      "Normandy -> PERSON\n",
      ", -> \n",
      "a -> \n",
      "region -> \n",
      "in -> \n",
      "France -> GPE\n",
      ". -> \n",
      "They -> \n",
      "were -> \n",
      "descended -> \n",
      "from -> \n",
      "Norse -> PERSON\n",
      "( -> \n",
      "\" -> \n",
      "Norman -> WORK_OF_ART\n",
      "\" -> \n",
      "comes -> \n",
      "from -> \n",
      "\" -> \n",
      "Norseman -> WORK_OF_ART\n",
      "\" -> \n",
      ") -> \n",
      "raiders -> \n",
      "and -> \n",
      "pirates -> \n",
      "from -> \n",
      "Denmark -> GPE\n",
      ", -> \n",
      "Iceland -> GPE\n",
      "and -> \n",
      "Norway -> GPE\n",
      "who -> \n",
      ", -> \n",
      "under -> \n",
      "their -> \n",
      "leader -> \n",
      "Rollo -> PERSON\n",
      ", -> \n",
      "agreed -> \n",
      "to -> \n",
      "swear -> \n",
      "fealty -> \n",
      "to -> \n",
      "King -> \n",
      "Charles -> PERSON\n",
      "III -> PERSON\n",
      "of -> \n",
      "West -> \n",
      "Francia -> \n",
      ". -> \n",
      "Through -> \n",
      "generations -> \n",
      "of -> \n",
      "assimilation -> \n",
      "and -> \n",
      "mixing -> \n",
      "with -> \n",
      "the -> \n",
      "native -> \n",
      "Frankish -> NORP\n",
      "and -> \n",
      "Roman -> NORP\n",
      "- -> NORP\n",
      "Gaulish -> NORP\n",
      "populations -> \n",
      ", -> \n",
      "their -> \n",
      "descendants -> \n",
      "would -> \n",
      "gradually -> \n",
      "merge -> \n",
      "with -> \n",
      "the -> \n",
      "Carolingian -> NORP\n",
      "- -> \n",
      "based -> \n",
      "cultures -> \n",
      "of -> \n",
      "West -> LOC\n",
      "Francia -> LOC\n",
      ". -> \n",
      "The -> \n",
      "distinct -> \n",
      "cultural -> \n",
      "and -> \n",
      "ethnic -> \n",
      "identity -> \n",
      "of -> \n",
      "the -> \n",
      "Normans -> ORG\n",
      "emerged -> \n",
      "initially -> \n",
      "in -> \n",
      "the -> DATE\n",
      "first -> DATE\n",
      "half -> DATE\n",
      "of -> DATE\n",
      "the -> DATE\n",
      "10th -> DATE\n",
      "century -> DATE\n",
      ", -> \n",
      "and -> \n",
      "it -> \n",
      "continued -> \n",
      "to -> \n",
      "evolve -> \n",
      "over -> \n",
      "the -> \n",
      "succeeding -> \n",
      "centuries -> DATE\n",
      ". -> \n"
     ]
    }
   ],
   "source": [
    "for item in lst:\n",
    "    print(item.text, '->', item.ent_type_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Normans,\n",
       " Norman,\n",
       " French,\n",
       " Latin,\n",
       " the 10th and 11th centuries,\n",
       " Normandy,\n",
       " France,\n",
       " Norse,\n",
       " Norman,\n",
       " Norseman,\n",
       " Denmark,\n",
       " Iceland,\n",
       " Norway,\n",
       " Rollo,\n",
       " Charles III,\n",
       " Frankish,\n",
       " Roman-Gaulish,\n",
       " Carolingian,\n",
       " West Francia,\n",
       " Normans,\n",
       " the first half of the 10th century,\n",
       " centuries)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_sample = \"In what country is Normandy located\"\n",
    "q_sample = \"Who is responsible for Normandy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = nlp(q_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Normandy]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(q.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

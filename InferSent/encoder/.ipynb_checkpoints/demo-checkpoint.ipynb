{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "from models import InferSent\n",
    "model_version = 1\n",
    "MODEL_PATH = \"../encoder/infersent%s.pkl\" % model_version\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': model_version}\n",
    "model = InferSent(params_model)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep it on CPU or put it on GPU\n",
    "use_cuda = False\n",
    "model = model.cuda() if use_cuda else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If infersent1 -> use GloVe embeddings. If infersent2 -> use InferSent embeddings.\n",
    "W2V_PATH = '../dataset/GloVe/glove.840B.300d.txt' if model_version == 1 else '../dataset/fastText/crawl-300d-2M.vec'\n",
    "model.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings of K most frequent words\n",
    "model.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filename):\n",
    "    with open(\"../../data/\" + filename + \".pickle\", \"rb\") as pickling_on:\n",
    "        obj = pickle.load(pickling_on)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_pickle(\"train_context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.context.values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"../../data/training.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_json(\"../../data/development.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'title': 'Beyoncé', 'paragraphs': [{'context'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'title': 'Frédéric_Chopin', 'paragraphs': [{'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'title': 'Sino-Tibetan_relations_during_the_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'title': 'IPod', 'paragraphs': [{'context': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'title': 'The_Legend_of_Zelda:_Twilight_Princ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data\n",
       "0  {'title': 'Beyoncé', 'paragraphs': [{'context'...\n",
       "1  {'title': 'Frédéric_Chopin', 'paragraphs': [{'...\n",
       "2  {'title': 'Sino-Tibetan_relations_during_the_M...\n",
       "3  {'title': 'IPod', 'paragraphs': [{'context': '...\n",
       "4  {'title': 'The_Legend_of_Zelda:_Twilight_Princ..."
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'The Legend of Zelda: Twilight Princess (Japanese: ゼルダの伝説 トワイライトプリンセス, Hepburn: Zeruda no Densetsu: Towairaito Purinsesu?) is an action-adventure game developed and published by Nintendo for the GameCube and Wii home video game consoles. It is the thirteenth installment in the The Legend of Zelda series. Originally planned for release on the GameCube in November 2005, Twilight Princess was delayed by Nintendo to allow its developers to refine the game, add more content, and port it to the Wii. The Wii version was released alongside the console in North America in November 2006, and in Japan, Europe, and Australia the following month. The GameCube version was released worldwide in December 2006.[b]',\n",
       " 'qas': [{'question': 'What year was the Wii version of Legend of Zelda: Twilight Princess released?',\n",
       "   'id': '56d1159e17492d1400aab8cf',\n",
       "   'answers': [{'text': '2006', 'answer_start': 578}],\n",
       "   'is_impossible': False},\n",
       "  {'plausible_answers': [{'text': 'GameCube and Wii', 'answer_start': 194}],\n",
       "   'question': 'What consoles can be used to play Australia Twilight?',\n",
       "   'id': '5a8d7bf7df8bba001a0f9ab2',\n",
       "   'answers': [],\n",
       "   'is_impossible': True},\n",
       "  {'plausible_answers': [{'text': '2005', 'answer_start': 364}],\n",
       "   'question': 'What year was the Legend of Zelda: Australian Princess originally planned for release?',\n",
       "   'id': '5a8d7bf7df8bba001a0f9ab5',\n",
       "   'answers': [],\n",
       "   'is_impossible': True},\n",
       "  {'plausible_answers': [{'text': 'action-adventure', 'answer_start': 128}],\n",
       "   'question': 'What category of game is Legend of Zelda: Australia Twilight?',\n",
       "   'id': '5a8d7bf7df8bba001a0f9ab1',\n",
       "   'answers': [],\n",
       "   'is_impossible': True},\n",
       "  {'question': 'What year was the Legend of Zelda:Twilight Princess originally planned for release?',\n",
       "   'id': '56d1159e17492d1400aab8ce',\n",
       "   'answers': [{'text': '2005', 'answer_start': 364}],\n",
       "   'is_impossible': False},\n",
       "  {'plausible_answers': [{'text': 'November 2006', 'answer_start': 569}],\n",
       "   'question': 'When was Australia Twilight launched in North America?',\n",
       "   'id': '5a8d7bf7df8bba001a0f9ab3',\n",
       "   'answers': [],\n",
       "   'is_impossible': True}]}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[4,0]['paragraphs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "questions = []\n",
    "answers_text = []\n",
    "answers_start = []\n",
    "is_impossible = []\n",
    "for i in range(train.shape[0]):\n",
    "    topic = train.iloc[i,0]['paragraphs']\n",
    "    for sub_para in topic:\n",
    "        for q_a in sub_para['qas']:\n",
    "            questions.append(q_a['question'])\n",
    "            answers_start.append(q_a['answers'][0]['answer_start'] if len(q_a['answers']) > 0 else None)\n",
    "            answers_text.append(q_a['answers'][0]['text'] if len(q_a['answers']) > 0 else None)\n",
    "            is_impossible.append(q_a['is_impossible'])\n",
    "            contexts.append(sub_para['context'])   \n",
    "df = pd.DataFrame({\"context\":contexts, \"question\": questions, \"answer_start\": answers_start, \"text\": answers_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69596, 4)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = list(df[\"context\"].drop_duplicates().reset_index(drop= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17766"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\" \".join(paras))\n",
    "sentences = [item.raw for item in blob.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87723"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 86905(/107041) words with w2v vectors\n",
      "Vocab size : 86905\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(sentences, tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_embeddings = {}\n",
    "for i in range(len(sentences)):\n",
    "    dict_embeddings[sentences[i]] = model.encode([sentences[i]], tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = list(df[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(questions)):\n",
    "    print(i)\n",
    "    dict_embeddings[questions[i]] = infersent.encode([questions[i]], tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {key:dict_embeddings[key] for i, key in enumerate(dict_embeddings) if i % 2 == 0}\n",
    "d2 = {key:dict_embeddings[key] for i, key in enumerate(dict_embeddings) if i % 2 == 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dict_embeddings1.pickle', 'wb') as handle:\n",
    "    pickle.dump(d1, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dict_embeddings2.pickle', 'wb') as handle:\n",
    "    pickle.dump(d2, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some sentences\n",
    "sentences = []\n",
    "with open('samples.txt') as f:\n",
    "    for line in f:\n",
    "        sentences.append(line.strip())\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stack = pd.read_csv(\"../../Stanford_politeness_corpus/stack-exchange.annotated.csv\", index_col=1)\n",
    "df_wiki = pd.read_csv(\"../../Stanford_politeness_corpus/wikipedia.annotated.csv\", index_col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_stack, df_wiki])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Community</th>\n",
       "      <th>Request</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Score2</th>\n",
       "      <th>Score3</th>\n",
       "      <th>Score4</th>\n",
       "      <th>Score5</th>\n",
       "      <th>TurkId1</th>\n",
       "      <th>TurkId2</th>\n",
       "      <th>TurkId3</th>\n",
       "      <th>TurkId4</th>\n",
       "      <th>TurkId5</th>\n",
       "      <th>Normalized Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3210318</th>\n",
       "      <td>092011 Stack Overflow</td>\n",
       "      <td>Can you explain more in detail, what should I ...</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>A33SMNMTMIOJ6T</td>\n",
       "      <td>A2OXXHGAM7B0Y</td>\n",
       "      <td>A28TXBSZPWMEU9</td>\n",
       "      <td>A3EJ5TT2ZGBIDA</td>\n",
       "      <td>A3OY0OL2M0HUTT</td>\n",
       "      <td>0.217326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314703</th>\n",
       "      <td>092011 Stack Overflow</td>\n",
       "      <td>Will expressions always be unambiguously paren...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>A1UIH2IMG9DV95</td>\n",
       "      <td>A23FB7HE970AZJ</td>\n",
       "      <td>A17G2LOYX7WQZ</td>\n",
       "      <td>A2BKPNKU3EG41Z</td>\n",
       "      <td>A3L459M9ME6WKI</td>\n",
       "      <td>0.063302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740262</th>\n",
       "      <td>092011 Stack Overflow</td>\n",
       "      <td>how are you resolving function pointers? I am ...</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>A1BS64O3JY0YJ4</td>\n",
       "      <td>A2AE4MZVUX9JPX</td>\n",
       "      <td>ARJ44YPGA2FPK</td>\n",
       "      <td>A14TK8NCD4CUN1</td>\n",
       "      <td>A17G2LOYX7WQZ</td>\n",
       "      <td>0.128902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6972808</th>\n",
       "      <td>092011 Stack Overflow</td>\n",
       "      <td>What is the definition of `buffer`? Is it a lo...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>A3VJDU2VRMN05L</td>\n",
       "      <td>A1ZHP80O13CEUI</td>\n",
       "      <td>A28TXBSZPWMEU9</td>\n",
       "      <td>A3MMLCBV2W3BP9</td>\n",
       "      <td>A2BKPNKU3EG41Z</td>\n",
       "      <td>0.240188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269106</th>\n",
       "      <td>092011 Stack Overflow</td>\n",
       "      <td>Is `A` a global variable?  What is x?</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>A3OW54MEVDKXJL</td>\n",
       "      <td>A2RDZ580VXUO1X</td>\n",
       "      <td>A872FSFU7WV6W</td>\n",
       "      <td>A1HBDQ0BJQBA4Q</td>\n",
       "      <td>A34M93NJC830DP</td>\n",
       "      <td>0.508284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Community  \\\n",
       "Id                               \n",
       "3210318  092011 Stack Overflow   \n",
       "1314703  092011 Stack Overflow   \n",
       "4740262  092011 Stack Overflow   \n",
       "6972808  092011 Stack Overflow   \n",
       "5269106  092011 Stack Overflow   \n",
       "\n",
       "                                                   Request  Score1  Score2  \\\n",
       "Id                                                                           \n",
       "3210318  Can you explain more in detail, what should I ...      12      16   \n",
       "1314703  Will expressions always be unambiguously paren...      13      13   \n",
       "4740262  how are you resolving function pointers? I am ...      13      15   \n",
       "6972808  What is the definition of `buffer`? Is it a lo...      13      13   \n",
       "5269106              Is `A` a global variable?  What is x?      17      18   \n",
       "\n",
       "         Score3  Score4  Score5         TurkId1         TurkId2  \\\n",
       "Id                                                                \n",
       "3210318      15      16      13  A33SMNMTMIOJ6T   A2OXXHGAM7B0Y   \n",
       "1314703      18      14      12  A1UIH2IMG9DV95  A23FB7HE970AZJ   \n",
       "4740262      17      13      17  A1BS64O3JY0YJ4  A2AE4MZVUX9JPX   \n",
       "6972808      13      13      19  A3VJDU2VRMN05L  A1ZHP80O13CEUI   \n",
       "5269106      16      16      13  A3OW54MEVDKXJL  A2RDZ580VXUO1X   \n",
       "\n",
       "                TurkId3         TurkId4         TurkId5  Normalized Score  \n",
       "Id                                                                         \n",
       "3210318  A28TXBSZPWMEU9  A3EJ5TT2ZGBIDA  A3OY0OL2M0HUTT          0.217326  \n",
       "1314703   A17G2LOYX7WQZ  A2BKPNKU3EG41Z  A3L459M9ME6WKI          0.063302  \n",
       "4740262   ARJ44YPGA2FPK  A14TK8NCD4CUN1   A17G2LOYX7WQZ          0.128902  \n",
       "6972808  A28TXBSZPWMEU9  A3MMLCBV2W3BP9  A2BKPNKU3EG41Z          0.240188  \n",
       "5269106   A872FSFU7WV6W  A1HBDQ0BJQBA4Q  A34M93NJC830DP          0.508284  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get sentence list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = [(k, v[\"Request\"]) for k, v in df[[\"Request\"]].to_dict(\"index\").items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10755"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu mode : >> 1000 sentences/s\n",
    "# cpu mode : ~100 sentences/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode([i[1] for i in requests], bsize=128, tokenize=False, verbose=True)\n",
    "print('nb sentences encoded : {0}'.format(len(embeddings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 11/16 (68.8%)\n",
      "Speed : 2.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 19/26 (73.1%)\n",
      "Speed : 2.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 23/25 (92.0%)\n",
      "Speed : 1.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/13 (84.6%)\n",
      "Speed : 3.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/10 (70.0%)\n",
      "Speed : 6.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 13/15 (86.7%)\n",
      "Speed : 3.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/11 (72.7%)\n",
      "Speed : 5.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 24/28 (85.7%)\n",
      "Speed : 1.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/16 (87.5%)\n",
      "Speed : 3.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/16 (87.5%)\n",
      "Speed : 1.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/12 (83.3%)\n",
      "Speed : 3.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 20/22 (90.9%)\n",
      "Speed : 2.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 24/28 (85.7%)\n",
      "Speed : 1.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 26/31 (83.9%)\n",
      "Speed : 1.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 48/51 (94.1%)\n",
      "Speed : 0.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/18 (66.7%)\n",
      "Speed : 3.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/12 (75.0%)\n",
      "Speed : 4.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/15 (80.0%)\n",
      "Speed : 2.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 28/29 (96.6%)\n",
      "Speed : 1.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 43/50 (86.0%)\n",
      "Speed : 0.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 26/30 (86.7%)\n",
      "Speed : 1.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 25/31 (80.6%)\n",
      "Speed : 1.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 30/35 (85.7%)\n",
      "Speed : 1.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 3/6 (50.0%)\n",
      "Speed : 14.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 30/34 (88.2%)\n",
      "Speed : 1.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/14 (85.7%)\n",
      "Speed : 3.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 19/21 (90.5%)\n",
      "Speed : 2.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/18 (77.8%)\n",
      "Speed : 3.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/12 (66.7%)\n",
      "Speed : 5.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/11 (81.8%)\n",
      "Speed : 4.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/15 (80.0%)\n",
      "Speed : 2.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/19 (73.7%)\n",
      "Speed : 2.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 19/25 (76.0%)\n",
      "Speed : 1.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/11 (81.8%)\n",
      "Speed : 4.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/11 (81.8%)\n",
      "Speed : 3.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 26/27 (96.3%)\n",
      "Speed : 1.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 20/32 (62.5%)\n",
      "Speed : 1.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 32/39 (82.1%)\n",
      "Speed : 1.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 23/28 (82.1%)\n",
      "Speed : 1.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 35/40 (87.5%)\n",
      "Speed : 1.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/14 (71.4%)\n",
      "Speed : 4.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/14 (71.4%)\n",
      "Speed : 3.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/14 (85.7%)\n",
      "Speed : 3.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 6/8 (75.0%)\n",
      "Speed : 7.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/16 (87.5%)\n",
      "Speed : 2.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 13/18 (72.2%)\n",
      "Speed : 3.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 19/22 (86.4%)\n",
      "Speed : 1.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 19/22 (86.4%)\n",
      "Speed : 2.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/11 (72.7%)\n",
      "Speed : 5.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/15 (73.3%)\n",
      "Speed : 3.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 23/29 (79.3%)\n",
      "Speed : 1.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/12 (75.0%)\n",
      "Speed : 3.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/9 (77.8%)\n",
      "Speed : 6.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/11 (63.6%)\n",
      "Speed : 5.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/16 (75.0%)\n",
      "Speed : 3.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/10 (70.0%)\n",
      "Speed : 6.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 25/28 (89.3%)\n",
      "Speed : 1.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/13 (84.6%)\n",
      "Speed : 2.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 15/18 (83.3%)\n",
      "Speed : 2.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 13/15 (86.7%)\n",
      "Speed : 2.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 27/32 (84.4%)\n",
      "Speed : 1.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 51/59 (86.4%)\n",
      "Speed : 0.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 19/23 (82.6%)\n",
      "Speed : 2.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 23/27 (85.2%)\n",
      "Speed : 1.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 27/29 (93.1%)\n",
      "Speed : 1.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 34/41 (82.9%)\n",
      "Speed : 1.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/11 (72.7%)\n",
      "Speed : 4.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 29/34 (85.3%)\n",
      "Speed : 1.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/14 (78.6%)\n",
      "Speed : 3.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 16/21 (76.2%)\n",
      "Speed : 2.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 19/21 (90.5%)\n",
      "Speed : 2.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 18/23 (78.3%)\n",
      "Speed : 2.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/20 (70.0%)\n",
      "Speed : 3.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/10 (80.0%)\n",
      "Speed : 5.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 22/24 (91.7%)\n",
      "Speed : 2.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 21/24 (87.5%)\n",
      "Speed : 2.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 18/25 (72.0%)\n",
      "Speed : 2.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 15/21 (71.4%)\n",
      "Speed : 3.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/12 (66.7%)\n",
      "Speed : 5.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/12 (83.3%)\n",
      "Speed : 4.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 26/34 (76.5%)\n",
      "Speed : 1.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 18/20 (90.0%)\n",
      "Speed : 2.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 24/29 (82.8%)\n",
      "Speed : 1.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 13/16 (81.2%)\n",
      "Speed : 3.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/14 (64.3%)\n",
      "Speed : 4.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 15/19 (78.9%)\n",
      "Speed : 2.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 26/32 (81.2%)\n",
      "Speed : 1.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 36/42 (85.7%)\n",
      "Speed : 1.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/12 (75.0%)\n",
      "Speed : 4.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 25/29 (86.2%)\n",
      "Speed : 1.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/12 (75.0%)\n",
      "Speed : 5.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 13/16 (81.2%)\n",
      "Speed : 3.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/9 (77.8%)\n",
      "Speed : 5.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 43/48 (89.6%)\n",
      "Speed : 1.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/12 (83.3%)\n",
      "Speed : 4.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 20/26 (76.9%)\n",
      "Speed : 2.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/13 (84.6%)\n",
      "Speed : 3.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 13/17 (76.5%)\n",
      "Speed : 3.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 21/23 (91.3%)\n",
      "Speed : 2.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/15 (73.3%)\n",
      "Speed : 3.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/15 (80.0%)\n",
      "Speed : 3.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/13 (84.6%)\n",
      "Speed : 3.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 20/26 (76.9%)\n",
      "Speed : 2.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 23/28 (82.1%)\n",
      "Speed : 1.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/11 (81.8%)\n",
      "Speed : 4.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/15 (73.3%)\n",
      "Speed : 3.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 15/18 (83.3%)\n",
      "Speed : 3.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 13/17 (76.5%)\n",
      "Speed : 3.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/15 (66.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed : 4.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 19/21 (90.5%)\n",
      "Speed : 2.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 9/13 (69.2%)\n",
      "Speed : 4.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 18/21 (85.7%)\n",
      "Speed : 2.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 17/21 (81.0%)\n",
      "Speed : 2.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/16 (87.5%)\n",
      "Speed : 3.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/12 (83.3%)\n",
      "Speed : 4.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/12 (66.7%)\n",
      "Speed : 5.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/19 (73.7%)\n",
      "Speed : 2.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/18 (77.8%)\n",
      "Speed : 3.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/13 (76.9%)\n",
      "Speed : 4.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 31/35 (88.6%)\n",
      "Speed : 1.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 13/15 (86.7%)\n",
      "Speed : 3.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 22/28 (78.6%)\n",
      "Speed : 1.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 13/18 (72.2%)\n",
      "Speed : 3.5 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 19/23 (82.6%)\n",
      "Speed : 2.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/15 (80.0%)\n",
      "Speed : 3.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 22/25 (88.0%)\n",
      "Speed : 1.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 19/23 (82.6%)\n",
      "Speed : 2.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 26/31 (83.9%)\n",
      "Speed : 1.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/10 (70.0%)\n",
      "Speed : 6.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/11 (90.9%)\n",
      "Speed : 4.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/12 (66.7%)\n",
      "Speed : 5.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/17 (82.4%)\n",
      "Speed : 2.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 19/20 (95.0%)\n",
      "Speed : 2.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 19/23 (82.6%)\n",
      "Speed : 2.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 25/30 (83.3%)\n",
      "Speed : 1.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 20/24 (83.3%)\n",
      "Speed : 1.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/14 (85.7%)\n",
      "Speed : 3.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 27/32 (84.4%)\n",
      "Speed : 1.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 21/25 (84.0%)\n",
      "Speed : 1.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/16 (68.8%)\n",
      "Speed : 3.6 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 13/16 (81.2%)\n",
      "Speed : 3.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 38/43 (88.4%)\n",
      "Speed : 1.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 16/24 (66.7%)\n",
      "Speed : 2.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 25/28 (89.3%)\n",
      "Speed : 1.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 22/22 (100.0%)\n",
      "Speed : 2.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 11/13 (84.6%)\n",
      "Speed : 3.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 12/14 (85.7%)\n",
      "Speed : 3.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/11 (72.7%)\n",
      "Speed : 5.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 10/18 (55.6%)\n",
      "Speed : 3.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/17 (82.4%)\n",
      "Speed : 2.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 32/32 (100.0%)\n",
      "Speed : 1.2 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 30/37 (81.1%)\n",
      "Speed : 1.4 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 14/17 (82.4%)\n",
      "Speed : 2.8 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 8/12 (66.7%)\n",
      "Speed : 5.1 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 18/22 (81.8%)\n",
      "Speed : 2.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 20/25 (80.0%)\n",
      "Speed : 1.9 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 20/26 (76.9%)\n",
      "Speed : 2.0 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 7/11 (63.6%)\n",
      "Speed : 5.7 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 31/37 (83.8%)\n",
      "Speed : 1.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 32/36 (88.9%)\n",
      "Speed : 1.3 sentences/s (cpu mode, bsize=128)\n",
      "Nb words kept : 28/35 (80.0%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2b65165bdebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mid_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-2b65165bdebd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mid_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/politeness/python3_spacy/recommendations/InferSent/encoder/models.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, bsize, tokenize, verbose)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstidx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbsize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/politeness/python3_spacy/recommendations/InferSent/encoder/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_tuple)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Handling padding in Recurrent Networks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0msent_packed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_len_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0msent_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_packed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# seqlen x batch x 2*nhid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0msent_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mingate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforgetgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/politeness/python3_spacy/politeness/venv/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "id_embs = [(k, model.encode([v], bsize=128, tokenize=False, verbose=True)[0]) for k, v in requests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_req = \"...\"\n",
    "new_emb = model.encode([new_req])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(id_emb):\n",
    "    return np.dot(new_emb, id_emb[1]) / (np.linalg.norm(new_emb) * np.linalg.norm(id_emb[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = min(id_embs, key=lambda x : cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rid, remb = ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[rid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(model.encode(['the cat eats.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine(model.encode(['the cat eats.'])[0], model.encode(['the cat drinks.'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = randint(0, len(sentences))\n",
    "_, _ = model.visualize(sentences[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sent = 'The cat is drinking milk.'\n",
    "_, _ = model.visualize(my_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab_k_words(500000) # getting 500K words vocab\n",
    "my_sent = 'barack-obama is the former president of the United-States.'\n",
    "_, _ = model.visualize(my_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
